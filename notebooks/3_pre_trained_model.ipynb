{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Lighthouse Labs/LLM-Project/notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUKOPQXEleb4",
        "outputId": "31e39195-3102-4ac9-fe4d-903a4059be11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Lighthouse Labs/LLM-Project/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaIswnZAlGyb",
        "outputId": "2e192fa5-beef-4b7c-8e99-d8730d1db764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer\n",
        "import torch\n",
        "import evaluate\n",
        "import os\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "tokenized_ds = load_from_disk(\"/content/drive/MyDrive/Lighthouse Labs/LLM-Project/notebooks/tokenized_imdb\")\n"
      ],
      "metadata": {
        "id": "Q6jMkb47lJv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use DistilBERT for sentiment classification\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2)  # IMDB is binary (pos/neg)"
      ],
      "metadata": {
        "id": "an5cHcthlrwt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376,
          "referenced_widgets": [
            "f36a465d6b2e441d9513e8c83c1a4a15",
            "a828f2004458424a9373d888d1a28467",
            "93c17bfbdb444497a017fd2cb6f6a24c",
            "e39d1922542b4d1fb5d2c4f122e1d10e",
            "f972496ff611476bb77a17c9444c3246",
            "d18dd3ebaadc401783914d8ba127a6d7",
            "d357d7d4b36b489098a94cfdee45c7ad",
            "da98f9683fb1419f8091334d5ff68f18",
            "69d92df9d8864a05a4899a07c6ac8fe3",
            "c29bf101cf09440986d266472cd1293e",
            "ebae5ae7d7964b03868f029d2fda7fb4",
            "e65cbb1112b044c48ced09c189361e82",
            "3a9eae68b46a4acfad439af17963ccbd",
            "9956cdeb10cd462d93b55ed4d6056863",
            "ba8b664b24964a49a9d1a3c140380511",
            "04e60b05e6744afa9c39e2f473805b40",
            "4aa35116a1e54430aa9946b86b6d4b68",
            "883e3d88774d4587b4dc76d7b4ada05d",
            "20ecf25fe4cf49029711de3204e5c303",
            "1c736b3ad51b4d0f9fb4902c3e6fbb75",
            "27cee33c6ba747a0a3f2c2ed93bf0e9a",
            "d2db2f6c5d39471e9bd377357b6bf9a8",
            "e50f7320c35e48e8af57b05bd5ed4fc2",
            "20509b48c1704fbf9226fb89d46c8362",
            "70b605a88b014224a889056b3a69d98b",
            "e3441a84c144456095825ed5ac61905a",
            "a5165679992a444d84577d32fd4316fa",
            "adc7cb434ab34143b73191532b0c886b",
            "e0e2978aaf3c4c21b32efaeb7462855f",
            "95adb01b786e4e97909443917d4f0d96",
            "a589dbb34bb24a7fbe9384e547ac8879",
            "46827aa500e44ebbb48a78d9e928fd89",
            "969a9474501f43799c86304d66884e5e",
            "0f615bb8537544d0ab98b0cfa208f21e",
            "24196d63008e489baf64f48210e4485d",
            "0a25247722b846688e03fd86cc3932c9",
            "41c6ff1884674a4f9aa1f643403cd168",
            "da00d700099341cd9ebb8b41ef61628e",
            "02abf397fa1d4a29a61fc353033549fc",
            "6aaf0d26f7d5479eb5161921466f73e5",
            "00506d0a76cb4c9dae02b61c683733dc",
            "6953886ad63b4cc29ea678f0fb6fffa7",
            "dd52c8d834a14050b2098e8fdbf24d1d",
            "30a2079a5e33464dbc5c922c738af27d",
            "010448d1c53e4a7e8ea393c70fb80964",
            "7c2fc08a0eb14a259f94cad912797289",
            "8d15a3bba81247268b4b1b5543655328",
            "c79595959b1f4b6da27b935828b5b9ed",
            "5266ed9b53ef48609e6402410084d6dd",
            "46127598ef424c1fafc84bef37411e86",
            "84fec8bbe3ba4631ba503d94323be443",
            "ff41bc33fe464d5aa31ee3396386eaa5",
            "f661b65507d049eda4c6195ca0acced2",
            "9e3d1aca90ec41e19779d36d98a1d1ed",
            "9270a5fde22e40639f26f8f102f8e96d"
          ]
        },
        "outputId": "e7f0d423-130b-44a6-e43a-e53d4b8599b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f36a465d6b2e441d9513e8c83c1a4a15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e65cbb1112b044c48ced09c189361e82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e50f7320c35e48e8af57b05bd5ed4fc2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f615bb8537544d0ab98b0cfa208f21e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "010448d1c53e4a7e8ea393c70fb80964"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce GPU usage: use only 10-20% of data\n",
        "small_train_ds = tokenized_ds[\"train\"].shuffle(seed=42).select(range(int(0.2 * len(tokenized_ds[\"train\"]))))\n",
        "small_test_ds = tokenized_ds[\"test\"].shuffle(seed=42).select(range(int(0.2 * len(tokenized_ds[\"test\"]))))"
      ],
      "metadata": {
        "id": "J0neIfm7sBP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Disable wandb and optimize GPU\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "5lPRx1qN50T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sxwfObujzyv",
        "outputId": "06353055-6de8-45ec-909c-fdf528d3d291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-13-926bbd0f7047>:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    fp16=True,  # Enables mixed precision for lower memory use\n",
        "    learning_rate=2e-5,\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_ds,\n",
        "    eval_dataset=small_test_ds,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "CjxpmBCGlSxd",
        "outputId": "dd0c07ae-85b9-4395-d860-8d5affd0f04d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 03:14, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.312900</td>\n",
              "      <td>0.286791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.202500</td>\n",
              "      <td>0.369405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.23568124389648437, metrics={'train_runtime': 194.7893, 'train_samples_per_second': 51.338, 'train_steps_per_second': 6.417, 'total_flos': 1324673986560000.0, 'train_loss': 0.23568124389648437, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save_pretrained(\"/content/drive/MyDrive/Lighthouse Labs/LLM-Project/notebooks/distilbert_sentiment_model\")"
      ],
      "metadata": {
        "id": "AfyTlp2JJCf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "je3JKKBjEcOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on smaller sample\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "small_eval = tokenized_ds[\"test\"].shuffle(seed=42).select(range(100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3489dba006694de098d37f9d612d724c",
            "d2c172b7403d419589d23e69a05618f7",
            "9665ef9a505f4deb92391f21251cc70a",
            "55846d16cc89487a9b342f04e6eed113",
            "1553aae194dd46ef87a923f35265b001",
            "d829c4130839488abe96a74d4c36d484",
            "a35512e7159746869a3acb3eca327dc0",
            "70acb5b4954745ada2253dfeebe8bfac",
            "927004ae904b48a487ce7facea38a924",
            "3815eba8aebd408c8bc0198d4d027ddc",
            "7679a1d824a7433eabe50927af0a7e7b"
          ]
        },
        "id": "btxZforoM7hE",
        "outputId": "1e4b9146-4f50-49d7-cc47-9867c9d0a8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3489dba006694de098d37f9d612d724c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(small_eval)\n",
        "predictions = torch.argmax(torch.tensor(preds.predictions), dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZLtzLzQdNSwR",
        "outputId": "222dd4ee-67bb-4524-e322-811ac83344f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy\n",
        "results = metric.compute(predictions=predictions, references=small_eval[\"label\"])\n",
        "print(\"Accuracy:\", results[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "Egvvbz3EAncN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d22ce5f-5d1d-4646-8c44-b1ea4c4c1a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample results with sentiment labels\n",
        "print(\"\\nSample Sentiment Analysis Results:\")\n",
        "for i in range(3):  # Adjust number of samples shown\n",
        "    review = small_eval[i]['text'][:300]  # First 300 characters\n",
        "    label = \"Positive\" if small_eval[i]['label'] == 1 else \"Negative\"\n",
        "    prediction = \"Positive\" if preds.predictions[i].argmax() == 1 else \"Negative\"\n",
        "\n",
        "    print(f\"Review:\\n{review}...\\n\")\n",
        "    print(f\"True Sentiment: {label}\")\n",
        "    print(f\"Predicted Sentiment: {prediction}\")\n",
        "    print(\"-\" * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7Ac3bN7uWqo",
        "outputId": "0304ec8f-5d74-4911-ee18-c583d6ec7ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Sentiment Analysis Results:\n",
            "Review:\n",
            "when i unsuspectedly rented a thousand acres i thought i was in for an entertaining king lear story and of course michelle pfeiffer was in it so what could go wrong  very quickly however i realized that this story was about a thousand other things besides just acres i started crying and couldnt stop...\n",
            "\n",
            "True Sentiment: Positive\n",
            "Predicted Sentiment: Positive\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Review:\n",
            "this is the latest entry in the long series of films with the french agent oss  the french answer to james bond the series was launched in the early s and spawned at least eight films none of which was ever released in the us osscaironest of spies is a  eezy little comedy that should notrepeat not b...\n",
            "\n",
            "True Sentiment: Positive\n",
            "Predicted Sentiment: Positive\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Review:\n",
            "this movie was so frustrating everything seemed energetic and i was totally prepared to have a good time i at least thought id be able to stand it but i was wrong first the weird looping it was like watching americas funniest home videos the damn parents i hated them so much the stereotypical latino...\n",
            "\n",
            "True Sentiment: Negative\n",
            "Predicted Sentiment: Negative\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
    
  },
  "nbformat": 4,
  "nbformat_minor": 0
}